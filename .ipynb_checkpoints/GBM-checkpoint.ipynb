{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "import os\n",
    "import lightgbm as lgbm\n",
    "import optuna as opt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import gc\n",
    "import shap\n",
    "from scipy.stats import binom_test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/matthewlafferty/Dropbox/Kaggle/Tabular_Feb_2021/tabular-playground-series-feb-2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262658</th>\n",
       "      <td>437948</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244489</td>\n",
       "      <td>0.689357</td>\n",
       "      <td>0.637401</td>\n",
       "      <td>0.483618</td>\n",
       "      <td>0.297313</td>\n",
       "      <td>0.283682</td>\n",
       "      <td>0.852316</td>\n",
       "      <td>0.285454</td>\n",
       "      <td>0.701334</td>\n",
       "      <td>7.515493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113751</th>\n",
       "      <td>189563</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583045</td>\n",
       "      <td>0.930331</td>\n",
       "      <td>0.300816</td>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.224117</td>\n",
       "      <td>0.672991</td>\n",
       "      <td>0.351220</td>\n",
       "      <td>0.358266</td>\n",
       "      <td>0.775926</td>\n",
       "      <td>6.509431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190510</th>\n",
       "      <td>317720</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862581</td>\n",
       "      <td>0.729128</td>\n",
       "      <td>0.926942</td>\n",
       "      <td>0.880656</td>\n",
       "      <td>0.810298</td>\n",
       "      <td>0.849737</td>\n",
       "      <td>0.799923</td>\n",
       "      <td>0.753010</td>\n",
       "      <td>0.822090</td>\n",
       "      <td>6.647751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54397</th>\n",
       "      <td>90493</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293556</td>\n",
       "      <td>0.281192</td>\n",
       "      <td>0.324031</td>\n",
       "      <td>0.051493</td>\n",
       "      <td>0.182182</td>\n",
       "      <td>0.231336</td>\n",
       "      <td>0.176297</td>\n",
       "      <td>0.413605</td>\n",
       "      <td>0.307887</td>\n",
       "      <td>7.423009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99124</th>\n",
       "      <td>165106</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381412</td>\n",
       "      <td>0.427531</td>\n",
       "      <td>0.339106</td>\n",
       "      <td>0.424547</td>\n",
       "      <td>0.446630</td>\n",
       "      <td>0.652907</td>\n",
       "      <td>0.337916</td>\n",
       "      <td>0.374758</td>\n",
       "      <td>0.243413</td>\n",
       "      <td>7.222037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167945</th>\n",
       "      <td>279929</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495404</td>\n",
       "      <td>0.629675</td>\n",
       "      <td>0.281271</td>\n",
       "      <td>0.441942</td>\n",
       "      <td>0.831618</td>\n",
       "      <td>0.710934</td>\n",
       "      <td>0.712174</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>0.269952</td>\n",
       "      <td>8.311413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96789</th>\n",
       "      <td>161220</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734606</td>\n",
       "      <td>0.420961</td>\n",
       "      <td>0.490053</td>\n",
       "      <td>0.368205</td>\n",
       "      <td>0.802769</td>\n",
       "      <td>0.714048</td>\n",
       "      <td>0.354470</td>\n",
       "      <td>0.766466</td>\n",
       "      <td>0.696809</td>\n",
       "      <td>7.667045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110668</th>\n",
       "      <td>184265</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373630</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.284551</td>\n",
       "      <td>0.344584</td>\n",
       "      <td>0.776556</td>\n",
       "      <td>0.609952</td>\n",
       "      <td>0.567342</td>\n",
       "      <td>0.713616</td>\n",
       "      <td>0.419782</td>\n",
       "      <td>7.550896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130926</th>\n",
       "      <td>218168</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950352</td>\n",
       "      <td>0.697246</td>\n",
       "      <td>0.752149</td>\n",
       "      <td>0.864242</td>\n",
       "      <td>0.807975</td>\n",
       "      <td>0.546746</td>\n",
       "      <td>0.531759</td>\n",
       "      <td>0.841601</td>\n",
       "      <td>0.302457</td>\n",
       "      <td>8.068698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245046</th>\n",
       "      <td>408735</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385891</td>\n",
       "      <td>0.317842</td>\n",
       "      <td>0.578686</td>\n",
       "      <td>0.422686</td>\n",
       "      <td>0.489252</td>\n",
       "      <td>0.576573</td>\n",
       "      <td>0.651665</td>\n",
       "      <td>0.358783</td>\n",
       "      <td>0.284274</td>\n",
       "      <td>5.174548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont5  \\\n",
       "262658  437948    B    A    A    A    B    B    A    E    C  ...  0.244489   \n",
       "113751  189563    A    A    A    C    B    D    A    E    C  ...  0.583045   \n",
       "190510  317720    A    A    A    A    B    D    A    E    E  ...  0.862581   \n",
       "54397    90493    A    B    B    C    B    B    A    E    E  ...  0.293556   \n",
       "99124   165106    A    A    A    C    B    B    A    E    C  ...  0.381412   \n",
       "167945  279929    A    A    A    C    B    D    A    E    C  ...  0.495404   \n",
       "96789   161220    A    B    B    A    B    D    A    E    E  ...  0.734606   \n",
       "110668  184265    A    B    A    C    B    D    A    E    C  ...  0.373630   \n",
       "130926  218168    A    B    A    A    B    D    A    B    G  ...  0.950352   \n",
       "245046  408735    A    A    A    D    B    B    A    E    C  ...  0.385891   \n",
       "\n",
       "           cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\n",
       "262658  0.689357  0.637401  0.483618  0.297313  0.283682  0.852316  0.285454   \n",
       "113751  0.930331  0.300816  0.127790  0.224117  0.672991  0.351220  0.358266   \n",
       "190510  0.729128  0.926942  0.880656  0.810298  0.849737  0.799923  0.753010   \n",
       "54397   0.281192  0.324031  0.051493  0.182182  0.231336  0.176297  0.413605   \n",
       "99124   0.427531  0.339106  0.424547  0.446630  0.652907  0.337916  0.374758   \n",
       "167945  0.629675  0.281271  0.441942  0.831618  0.710934  0.712174  0.693807   \n",
       "96789   0.420961  0.490053  0.368205  0.802769  0.714048  0.354470  0.766466   \n",
       "110668  0.464400  0.284551  0.344584  0.776556  0.609952  0.567342  0.713616   \n",
       "130926  0.697246  0.752149  0.864242  0.807975  0.546746  0.531759  0.841601   \n",
       "245046  0.317842  0.578686  0.422686  0.489252  0.576573  0.651665  0.358783   \n",
       "\n",
       "          cont13    target  \n",
       "262658  0.701334  7.515493  \n",
       "113751  0.775926  6.509431  \n",
       "190510  0.822090  6.647751  \n",
       "54397   0.307887  7.423009  \n",
       "99124   0.243413  7.222037  \n",
       "167945  0.269952  8.311413  \n",
       "96789   0.696809  7.667045  \n",
       "110668  0.419782  7.550896  \n",
       "130926  0.302457  8.068698  \n",
       "245046  0.284274  5.174548  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          9\n",
       "1          6\n",
       "2         14\n",
       "3         11\n",
       "4          6\n",
       "          ..\n",
       "299995    12\n",
       "299996    12\n",
       "299997    13\n",
       "299998     6\n",
       "299999    11\n",
       "Length: 300000, dtype: int8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data['cat9'].astype('category').cat.codes\n",
    "test += 1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         I\n",
       "1         F\n",
       "2         N\n",
       "3         K\n",
       "4         F\n",
       "         ..\n",
       "299995    L\n",
       "299996    L\n",
       "299997    M\n",
       "299998    F\n",
       "299999    K\n",
       "Name: cat9, Length: 300000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cat9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_convert(X:pd.series) -> pd.Series:\n",
    "    temp = X.astype('category').cat.codes\n",
    "    temp += 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shadow_feature(X:pd.Series) -> np.array:\n",
    "    temp = X.to_numpy(copy=True)\n",
    "    np.random.shuffle(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_tune(X:pd.DataFrame, target:str, features:list, cat_features:list, num_boost_rounds:int, params:dict, nfolds:int=3, verbose_eval:bool = True, sample:float = 0.5) -> dict:\n",
    "    \n",
    "    X = X.sample(frac=sample)\n",
    "    \n",
    "    dtrain = lgbm.Dataset(data=X[features],\n",
    "                          label=X[target],\n",
    "                          feature_name=features)\n",
    "    \n",
    "    model = opt.integration.lightgbm.LightGBMTunerCV(params = params,\n",
    "                                                     train_set = dtrain,\n",
    "                                                     num_boost_round = num_boost_rounds,\n",
    "                                                     nfold = nfolds,\n",
    "                                                     #stratified = True,\n",
    "                                                     shuffle = True,\n",
    "                                                     feature_name=features,\n",
    "                                                     categorical_feature=cat_features,\n",
    "                                                     early_stopping_rounds=0.05*num_boost_rounds,\n",
    "                                                     verbose_eval = verbose_eval,\n",
    "                                                     seed = 51)\n",
    "    model.run()\n",
    "    print(model.best_score)\n",
    "    return model.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-02-16 15:14:09,326] A new study created in memory with name: no-name-a2d5586f-882b-430c-b498-81bba98c0565\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n",
      "[W 2021-02-16 15:14:09,333] Trial 0 failed because of the following error: ValueError('DataFrame.dtypes for data must be int, float or bool.\\nDid not expect the data types in the following fields: cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\", line 778, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 304, in __call__\n",
      "    cv_results = lgb.cv(self.lgbm_params, self.train_set, **self.lgbm_kwargs)\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\", line 535, in cv\n",
      "    eval_train_metric=eval_train_metric)\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\", line 302, in _make_n_folds\n",
      "    full_data = full_data.construct()\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\", line 1085, in construct\n",
      "    categorical_feature=self.categorical_feature, params=self.params)\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\", line 830, in _lazy_init\n",
      "    self.pandas_categorical)\n",
      "  File \"/Users/matthewlafferty/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\", line 344, in _data_from_pandas\n",
      "    + ', '.join(data.columns[bad_indices]))\n",
      "ValueError: DataFrame.dtypes for data must be int, float or bool.\n",
      "Did not expect the data types in the following fields: cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5b0adc7f7807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                        \u001b[0mnfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                        \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                        sample = 1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0ee15f5231bd>\u001b[0m in \u001b[0;36mparams_tune\u001b[0;34m(X, target, features, cat_features, num_boost_rounds, params, nfolds, verbose_eval, sample)\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                      \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                      seed = 51)\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_train_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_feature_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_num_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_bagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mtune_feature_fraction\u001b[0;34m(self, n_trials)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparam_values\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tune_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature_fraction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtune_num_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m_tune_params\u001b[0;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optuna_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             )\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 328\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m                 )\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    753\u001b[0m     ) -> None:\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cv_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    533\u001b[0m                             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpreproc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpreproc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                             \u001b[0mstratified\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                             eval_train_metric=eval_train_metric)\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;31m# setup callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36m_make_n_folds\u001b[0;34m(full_data, folds, nfold, params, seed, fpreproc, stratified, shuffle, eval_train_metric)\u001b[0m\n\u001b[1;32m    300\u001b[0m                   shuffle=True, eval_train_metric=False):\n\u001b[1;32m    301\u001b[0m     \u001b[0;34m\"\"\"Make a n-fold list of Booster from random indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mfull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mnum_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1086\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    828\u001b[0m                                                                                              \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m                                                                                              \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m                                                                                              self.pandas_categorical)\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    342\u001b[0m             raise ValueError(\"DataFrame.dtypes for data must be int, float or bool.\\n\"\n\u001b[1;32m    343\u001b[0m                              \u001b[0;34m\"Did not expect the data types in the following fields: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                              + ', '.join(data.columns[bad_indices]))\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: cat0, cat1, cat2, cat3, cat4, cat5, cat6, cat7, cat8, cat9"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'root_mean_squared_error',\n",
    "          'verbosity': -1,\n",
    "          'boosting_type': 'gbdt',\n",
    "          'learning_rate': 0.25}\n",
    "\n",
    "params_0 = params_tune(X=data,\n",
    "                       target='target',\n",
    "                       features=[x for x in list(data) if ('cat' in x) or ('cont' in x)],\n",
    "                       cat_features=[x for x in list(data) if ('cat' in x)],\n",
    "                       num_boost_rounds=5000,\n",
    "                       params=params,\n",
    "                       nfolds=3,\n",
    "                       verbose_eval=False,\n",
    "                       sample = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'learning_rate': 0.25,\n",
       " 'is_unbalanced': False,\n",
       " 'metric': 'auc',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 4.805704302063685e-07,\n",
       " 'lambda_l2': 6.497878684050329e-07,\n",
       " 'num_leaves': 189,\n",
       " 'feature_fraction': 0.7,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_0['metric'] = 'auc'\n",
    "params_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_shap(X:pd.DataFrame, features:list, target:str, params:dict, num_boost_rounds:int=10000, sample:float = 0.7, num_iter:int = 3) -> list:\n",
    "    \n",
    "    # We will determine optimal parameters on a random sample. We'll use these parameters to construct a new model for each iteration.\n",
    "    # Determining the hyperparameters takes time, so we'll do it once, and use these parameters to construct our models.\n",
    "    X_shadow = create_shadow_features(X, features)\n",
    "    \n",
    "    # These are the features, categorical features, and categorical feature indices that we will use once the shadow features are added.\n",
    "    shadow_features = features + [x + '_shadow' for x in features]\n",
    "                        \n",
    "    # This is the data frame that we will use to store our SHAP value information\n",
    "    results_df = pd.DataFrame(columns = shadow_features + [target])\n",
    "    \n",
    "    # With the parameters determined, we'll build models using the parameters on a random sample of records, determine the SHAP values on\n",
    "    # the remaining records.\n",
    "    for i in range(num_iter):\n",
    "        X_train, X_shap, y_train, y_shap = train_test_split(X_shadow[shadow_features], X_shadow[target], train_size=sample, shuffle=True, stratify=X_shadow[target])\n",
    "        \n",
    "        dtrain = lgbm.Dataset(data = X_train,\n",
    "                              label = y_train,\n",
    "                              feature_name = shadow_features)\n",
    "        \n",
    "        dval = lgbm.Dataset(data = X_shap,\n",
    "                            label = y_shap,\n",
    "                            feature_name = shadow_features)\n",
    "        \n",
    "        del(X_train, y_train)\n",
    "        gc.collect()\n",
    "        \n",
    "        current_model = lgbm.train(params=params,\n",
    "                                   train_set=dtrain,\n",
    "                                   num_boost_round=num_boost_rounds,\n",
    "                                   valid_sets=dval,\n",
    "                                   feature_name=shadow_features,\n",
    "                                   early_stopping_rounds=int(0.05*num_boost_rounds),\n",
    "                                   verbose_eval=100)\n",
    "        \n",
    "        shap_values = shap.TreeExplainer(current_model).shap_values(X_shap)\n",
    "        shap_values_df = pd.DataFrame(data = shap_values[1], columns = shadow_features)\n",
    "        shap_values_df[target] = np.where(y_shap == 1, 1, 0)\n",
    "        \n",
    "        print('Missing targets in y_shap = ', sum(y_shap.isna()))\n",
    "        print('Missing targets in y_shap = ', sum(y_shap))\n",
    "        print('Missing targets in shap_values_df = ', sum(shap_values_df['target'].isna()))\n",
    "        print('Missing targets in shap_values_df = ', sum(shap_values_df['target']))\n",
    "        \n",
    "        #print(results.shape)\n",
    "        #print(np.abs(shap_values[0]).mean(0))\n",
    "        print(results_df.shape)\n",
    "        #print(results_df.sample(10))\n",
    "        print(shap_values_df.shape)\n",
    "        print([x for x in list(results_df) if x not in list(shap_values_df)])\n",
    "        print([x for x in list(shap_values_df) if x not in list(results_df)])\n",
    "        #print(shap_values_df.sample(10))\n",
    "        results_df = pd.concat([results_df, shap_values_df], axis = 0)\n",
    "    \n",
    "    cols_to_keep = []\n",
    "    n = results_df.shape[0]\n",
    "    for col in features:\n",
    "        x = np.sum(np.where((results_df[target] == 0) & (results_df[col] < results_df[col + '_shadow']), 1,\n",
    "                        np.where((results_df[target] == 1) & (results_df[col] > results_df[col + '_shadow']), 1, 0)))\n",
    "        p_val = binom_test(x=x, n=n, p=0.5, alternative='greater')\n",
    "        if p_val <= 0.05:\n",
    "            cols_to_keep += [col]\n",
    "            \n",
    "    return cols_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds\n",
      "[100]\tvalid_0's auc: 0.615545\n",
      "[200]\tvalid_0's auc: 0.620539\n",
      "[300]\tvalid_0's auc: 0.622757\n",
      "[400]\tvalid_0's auc: 0.621391\n",
      "[500]\tvalid_0's auc: 0.62185\n",
      "[600]\tvalid_0's auc: 0.622995\n",
      "[700]\tvalid_0's auc: 0.624099\n",
      "[800]\tvalid_0's auc: 0.622831\n",
      "[900]\tvalid_0's auc: 0.625327\n",
      "[1000]\tvalid_0's auc: 0.624036\n",
      "[1100]\tvalid_0's auc: 0.625355\n",
      "[1200]\tvalid_0's auc: 0.626502\n",
      "[1300]\tvalid_0's auc: 0.626611\n",
      "[1400]\tvalid_0's auc: 0.626031\n",
      "[1500]\tvalid_0's auc: 0.626124\n",
      "[1600]\tvalid_0's auc: 0.625573\n",
      "[1700]\tvalid_0's auc: 0.625923\n",
      "[1800]\tvalid_0's auc: 0.625734\n",
      "[1900]\tvalid_0's auc: 0.626323\n",
      "[2000]\tvalid_0's auc: 0.6267\n",
      "[2100]\tvalid_0's auc: 0.627149\n",
      "[2200]\tvalid_0's auc: 0.626988\n",
      "[2300]\tvalid_0's auc: 0.626752\n",
      "[2400]\tvalid_0's auc: 0.626532\n",
      "[2500]\tvalid_0's auc: 0.625905\n",
      "[2600]\tvalid_0's auc: 0.626303\n",
      "[2700]\tvalid_0's auc: 0.626939\n",
      "[2800]\tvalid_0's auc: 0.62694\n",
      "[2900]\tvalid_0's auc: 0.626564\n",
      "[3000]\tvalid_0's auc: 0.627321\n",
      "Early stopping, best iteration is:\n",
      "[2054]\tvalid_0's auc: 0.627538\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = feature_selection_shap(X=data,\n",
    "                                          features=features,\n",
    "                                          target='target',\n",
    "                                          params=params_0,\n",
    "                                          num_boost_rounds=20000,\n",
    "                                          sample=0.7,\n",
    "                                          num_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resp']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgbm.Dataset(data=data[[x for x in features if x not in ['resp','weight']]],\n",
    "                          label=data['target'],\n",
    "                          feature_name=[x for x in features if x not in ['resp','weight']])\n",
    "\n",
    "test_params['metric'] = 'auc'\n",
    "test_model = lgbm.cv(params = test_params,\n",
    "                        train_set = dtrain,\n",
    "                        num_boost_round=10000,\n",
    "                        nfold=5,\n",
    "                        stratified=True,\n",
    "                        shuffle=True,\n",
    "                        metrics='auc',\n",
    "                        feature_name=[x for x in features if x not in ['resp','weight']],\n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_trees_tune(X:pd.DataFrame, target:str, features:list, num_boost_rounds:int, params:dict, learning_rate:float = 0.01, num_iter:int = 10, train_sample:float = 0.7, verbose_eval:int = 0):\n",
    "    \n",
    "    cat_features_indices = [i for i in range(len(features)) if features[i] in cat_features]\n",
    "    params['learning_rate'] = learning_rate\n",
    "    best_iter_list = []\n",
    "        \n",
    "    for i in range(num_iter):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X[features], X[target], train_size = train_sample, shuffle = True, stratify = X[target])\n",
    "        if len(cat_features) == 0:\n",
    "            X_train_smote, y_train_smote = SMOTE(random_state=51).fit_resample(X_train, y_train)\n",
    "        else:\n",
    "            X_train_smote, y_train_smote = SMOTENC(categorical_features=cat_features_indices, random_state=51).fit_resample(X_train, y_train)\n",
    "        \n",
    "        del(X_train, y_train)\n",
    "        gc.collect()\n",
    "        \n",
    "        dtrain = lgbm.Dataset(data = X_train_smote,\n",
    "                                label = y_train_smote,\n",
    "                                feature_name = features,\n",
    "                                categorical_feature = cat_features)\n",
    "        \n",
    "        dval = lgbm.Dataset(data = X_val,\n",
    "                            label = y_val,\n",
    "                            feature_name = features,\n",
    "                            categorical_feature = cat_features)\n",
    "        \n",
    "        del(X_train_smote, y_train_smote, X_val, y_val)\n",
    "        gc.collect()\n",
    "        \n",
    "        current_model = lgbm.train(params=params,\n",
    "                                    train_set=dtrain,\n",
    "                                    num_boost_round=num_boost_rounds,\n",
    "                                    valid_sets=[dval],\n",
    "                                    feature_name=features,\n",
    "                                    categorical_feature=cat_features,\n",
    "                                    early_stopping_rounds=1000,\n",
    "                                    verbose_eval=0)\n",
    "\n",
    "        best_iter_current = current_model.best_iteration\n",
    "        best_iter_list += [best_iter_current]\n",
    "        \n",
    "        print(current_model.best_score)\n",
    "\n",
    "    return int(np.nanmean(best_iter_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns = ['target', 'param', 'val'])\n",
    "\n",
    "params = {'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'verbosity': -1,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate': 0.25,\n",
    "            'is_unbalanced': False}\n",
    "    \n",
    "for target in targets:\n",
    "    train = train_all.copy()\n",
    "    augmented_vals = augmenting_vals(train, target, num = 20)\n",
    "    train = pd.concat([train, augmented_vals], axis = 0, ignore_index = True)\n",
    "    best_params = params_tune(X=train, target=target, features=features, cat_features=cat_features, num_boost_rounds=10000, params=params)\n",
    "    \n",
    "    features_to_keep = feature_selection_shap(X=train[features], y=train[target], params=best_params, features=features, cat_features=cat_features, sample=0.5, num_boost_rounds=10000, num_iter = 3, verbose_eval = 0)\n",
    "    cat_features_to_keep = [x for x in cat_features if x in features_to_keep]\n",
    "    \n",
    "    best_params['features'] = features_to_keep\n",
    "    best_params['cat_features'] = cat_features_to_keep\n",
    "    \n",
    "    num_trees = num_trees_tune(X=train, target=target, features=features_to_keep, cat_features=cat_features_to_keep, num_boost_rounds=50000, params=best_params, learning_rate = 0.01, num_iter = 10, train_sample = 0.7, verbose_eval = 0)\n",
    "    best_params['num_trees'] = int(1.1*num_trees)\n",
    "    \n",
    "    for key in best_params.keys():\n",
    "        results_df = pd.concat([results_df, pd.DataFrame(data=[[target, key, best_params[key]]], columns=['target', 'param', 'val'])], axis=0, ignore_index=True)\n",
    "    print(results_df.tail(10))\n",
    "    print(target, ' completed. ', len(targets) - targets.index(target) - 1, ' to go...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
